{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78fce8d8-21ba-4977-97b3-0b6608f579e5",
   "metadata": {},
   "source": [
    "# Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbf235c8-0d03-4da5-859b-cf1119a36f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 4256 graphs\n",
      "Validation set: 1222 graphs\n",
      "Test set: 602 graphs\n",
      "Proportion of '1's for each label in training set: [0.06343985 0.06414474 0.57307331 0.10103383 0.30451128]\n",
      "Proportion of '1's for each label in validation set: [0.06873977 0.06792144 0.57774141 0.09165303 0.30032733]\n",
      "Proportion of '1's for each label in test set: [0.04318937 0.06644518 0.57807309 0.09966777 0.3255814 ]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set working directory and define paths for input and output data\n",
    "work_dir = os.getcwd()  # Use the current directory as work_dir\n",
    "input_data_dir = os.path.join(work_dir, '../Data')  # Set ../Data as input data location\n",
    "output_dir = os.path.join(work_dir, '../Data')  # Set ../Data as input data location\n",
    "\n",
    "# Load the merged graph dataset with labels\n",
    "merged_file = os.path.join(input_data_dir, 'all_graphs_with_labels-train.pt')\n",
    "merged_graphs = torch.load(merged_file)\n",
    "\n",
    "# Extract labels from each graph in the dataset, converting to NumPy array\n",
    "labels = np.array([graph.y.numpy() if isinstance(graph.y, torch.Tensor) else graph.y for graph in merged_graphs])\n",
    "\n",
    "# Function to randomly split data into training and testing sets\n",
    "def random_train_test_split(graphs, labels, test_size=0.3, random_state=42):\n",
    "    \"\"\"Split graphs and labels into training and test sets using random split\"\"\"\n",
    "    train_graphs, test_graphs, train_labels, test_labels = train_test_split(\n",
    "        graphs, labels, test_size=test_size, random_state=random_state, shuffle=True)\n",
    "\n",
    "    return train_graphs, test_graphs, train_labels, test_labels\n",
    "\n",
    "# Split dataset into training (70%) and temporary (30%) sets\n",
    "train_graphs, temp_graphs, train_labels, temp_labels = random_train_test_split(\n",
    "    merged_graphs, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Further split the temporary set (30% of original) into validation (20%) and test sets (10%)\n",
    "val_graphs, test_graphs, val_labels, test_labels = random_train_test_split(\n",
    "    temp_graphs, temp_labels, test_size=0.33, random_state=42)\n",
    "\n",
    "# Function to calculate the proportion of '1's in each label across the labels dataset\n",
    "def calculate_label_proportions(labels):\n",
    "    proportions = np.mean(labels == 1, axis=0)  # Calculate the proportion of '1's for each label\n",
    "    return proportions\n",
    "\n",
    "# Calculate the proportion of '1's in each subset's labels\n",
    "train_proportions = calculate_label_proportions(train_labels)\n",
    "val_proportions = calculate_label_proportions(val_labels)\n",
    "test_proportions = calculate_label_proportions(test_labels)\n",
    "\n",
    "# Convert labels to torch.Tensor format for compatibility with PyTorch models\n",
    "train_labels = torch.tensor(train_labels)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "# Print the size of each subset\n",
    "print(f\"Training set: {len(train_graphs)} graphs\")\n",
    "print(f\"Validation set: {len(val_graphs)} graphs\")\n",
    "print(f\"Test set: {len(test_graphs)} graphs\")\n",
    "\n",
    "# Print the proportion of '1's in each label for each subset\n",
    "print(\"Proportion of '1's for each label in training set:\", train_proportions)\n",
    "print(\"Proportion of '1's for each label in validation set:\", val_proportions)\n",
    "print(\"Proportion of '1's for each label in test set:\", test_proportions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3d8a5e-f860-4df2-8f09-17be389c83cf",
   "metadata": {},
   "source": [
    "#  Graph Transformer Network Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd92950-0af5-4015-9226-356b2711ae8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerModel(\n",
      "  (embedding): Linear(in_features=91, out_features=128, bias=True)\n",
      "  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  (transformer_encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): CustomTransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (dropout): Dropout(p=0.3, inplace=False)\n",
      "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
      "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.3, inplace=False)\n",
      "        (dropout2): Dropout(p=0.3, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import global_add_pool\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Set random seed for reproducibility across random, numpy, and torch\n",
    "def set_seed(seed: int) -> None:\n",
    "    import random\n",
    "    import numpy as np\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # If using GPU\n",
    "\n",
    "set_seed(42)  # Set the random seed\n",
    "\n",
    "# Custom Transformer Encoder Layer to return attention weights\n",
    "class CustomTransformerEncoderLayer(TransformerEncoderLayer):\n",
    "    def forward(self, src: torch.Tensor) -> tuple:\n",
    "        # Calculate self-attention and return attention weights\n",
    "        attn_output, attn_weights = self.self_attn(src, src, src)\n",
    "        src = src + self.dropout1(attn_output)\n",
    "        src = self.norm1(src)\n",
    "        \n",
    "        # Apply feed-forward layer\n",
    "        ff_output = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
    "        src = src + self.dropout2(ff_output)\n",
    "        src = self.norm2(src)\n",
    "\n",
    "        return src, attn_weights\n",
    "\n",
    "# Transformer-based model definition\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, in_dim: int, hidden_dim: int, out_dim: int, num_heads: int, num_layers: int, dropout: float = 0.3, dosage_weight: float = 1.0):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.dosage_weight = dosage_weight  # Weight for dosage feature\n",
    "        self.num_layers = num_layers  # Store number of layers\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Linear(in_dim, hidden_dim)\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "        # Define the Transformer encoder layers\n",
    "        encoder_layers = CustomTransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads, dim_feedforward=hidden_dim, dropout=dropout, batch_first=True)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
    "        \n",
    "        # Global pooling\n",
    "        self.global_pool = global_add_pool\n",
    "        \n",
    "        # Fully connected output layer\n",
    "        self.fc = nn.Linear(hidden_dim, out_dim)\n",
    "        \n",
    "        # Dropout layer for regularization\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Initialize weights\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self) -> None:\n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        if self.embedding.bias is not None:\n",
    "            nn.init.zeros_(self.embedding.bias)\n",
    "        if self.fc.bias is not None:\n",
    "            nn.init.zeros_(self.fc.bias)\n",
    "\n",
    "    def forward(self, g) -> tuple:\n",
    "        x = g.x.clone()  # Clone input to avoid modifying the original data\n",
    "        x[:, 90] *= self.dosage_weight  # Apply dosage weight to feature at index 90\n",
    "\n",
    "        h = self.embedding(x)\n",
    "        h = self.norm(h)\n",
    "\n",
    "        # Transformer encoder, return attention weights\n",
    "        attn_weights_list = []\n",
    "        for _ in range(self.num_layers):\n",
    "            h, attn_weights = self.transformer_encoder.layers[_](h)\n",
    "            attn_weights_list.append(attn_weights)\n",
    "        \n",
    "        # Apply global pooling over node features to get graph-level features\n",
    "        hg = self.global_pool(h, g.batch)\n",
    "\n",
    "        hg = self.dropout(hg)\n",
    "        out = self.fc(hg)\n",
    "        \n",
    "        # Return the output, attention weights, and edge indices\n",
    "        edge_indices = g.edge_index  # Get edge indices from the graph data\n",
    "        return out, attn_weights_list, edge_indices\n",
    "\n",
    "# Model parameter configuration\n",
    "in_dim = 91          # Input feature dimension\n",
    "hidden_dim = 128     # Hidden layer dimension\n",
    "out_dim = 5          # Output dimension (e.g., number of classes)\n",
    "num_heads = 16       # Number of attention heads in Transformer\n",
    "num_layers = 1       # Number of Transformer encoder layers\n",
    "dropout = 0.3        # Dropout rate\n",
    "dosage_weight = 1    # Dosage weight for specific feature\n",
    "\n",
    "# Instantiate the Transformer model\n",
    "model = TransformerModel(in_dim, hidden_dim, out_dim, num_heads, num_layers, dropout, dosage_weight=dosage_weight)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8504c9-de39-47c1-8435-03e264add656",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f978db92-6714-4600-90b9-d0b91f924395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import recall_score, f1_score, precision_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Compute class weights to handle class imbalance in labels\n",
    "num_classes = train_labels.size(1)\n",
    "pos_counts = train_labels.sum(dim=0)\n",
    "neg_counts = train_labels.size(0) - pos_counts\n",
    "pos_weight = neg_counts / (pos_counts + 1e-6)\n",
    "\n",
    "# Define the loss function with class weights, optimizer, and learning rate scheduler\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "learning_rate = 0.0007\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
    "\n",
    "# Early stopping mechanism to halt training if validation loss doesn't improve\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience: int = 5, min_delta: float = 0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss: float) -> None:\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "# Print the current learning rate from the optimizer\n",
    "def print_learning_rate(optimizer) -> None:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(f\"Current Learning Rate: {param_group['lr']}\")\n",
    "\n",
    "# Data loading function to create batches of graphs and labels\n",
    "def create_batches(graphs, labels, batch_size: int) -> DataLoader:\n",
    "    for i, graph in enumerate(graphs):\n",
    "        graph.y = labels[i]  # Attach labels to graph data\n",
    "    return DataLoader(graphs, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Function to train the model\n",
    "def train_model(train_graphs, train_labels, val_graphs, val_labels, model, loss_fn, optimizer, scheduler, num_epochs: int = 50, batch_size: int = 32, early_stopping_patience: int = 5) -> None:\n",
    "    train_loader = create_batches(train_graphs, train_labels, batch_size)\n",
    "    val_loader = create_batches(val_graphs, val_labels, batch_size)\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=early_stopping_patience)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\"):\n",
    "            batch_graphs = batch\n",
    "            batch_labels = batch.y\n",
    "            \n",
    "            # Forward pass\n",
    "            output, attn_weights, edge_indices = model(batch_graphs)  # Unpack model's output\n",
    "            batch_labels = batch_labels.view(output.shape)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss = loss_fn(output, batch_labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Training Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # Validate the model\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_predictions = []\n",
    "        val_targets = []\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch_graphs = batch\n",
    "                batch_labels = batch.y\n",
    "                output, attn_weights, edge_indices = model(batch_graphs)  # Unpack model's output\n",
    "                batch_labels = batch_labels.view(output.shape)\n",
    "                loss = loss_fn(output, batch_labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                val_predictions.extend(torch.sigmoid(output).round().cpu().numpy())\n",
    "                val_targets.extend(batch_labels.cpu().numpy())\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        # Calculate recall, F1 score, and precision for validation set\n",
    "        recall = recall_score(val_targets, val_predictions, average='micro')\n",
    "        f1 = f1_score(val_targets, val_predictions, average='micro')\n",
    "        precision = precision_score(val_targets, val_predictions, average='micro')\n",
    "        \n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Validation Loss: {avg_val_loss:.4f}, \"\n",
    "              f\"Validation Recall: {recall:.4f}, Validation F1: {f1:.4f}, Validation Precision: {precision:.4f}\")\n",
    "        \n",
    "        # Step the learning rate scheduler\n",
    "        scheduler.step(avg_val_loss)\n",
    "        print_learning_rate(optimizer)\n",
    "        \n",
    "        # Check early stopping\n",
    "        early_stopping(avg_val_loss)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "# Train the model\n",
    "train_model(train_graphs, train_labels, val_graphs, val_labels, model, loss_fn, optimizer, scheduler, num_epochs=50, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a55c365-6015-4ab9-9d44-ca87ef6476e3",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49714928-b815-471c-888c-22d224a12c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Set global font to Arial for consistent plotting\n",
    "rcParams['font.family'] = 'Arial'\n",
    "\n",
    "# Function to evaluate the model on a specific dataset and optionally output attention weights\n",
    "def evaluate_model(graphs, labels, model, output_dir, data_name, cpm_id=None):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "    all_attn_weights = []\n",
    "    all_edge_indices = []  # New: store edge indices for each graph\n",
    "\n",
    "    # Collect predictions, labels, attention weights, and edge indices for the dataset\n",
    "    with torch.no_grad():\n",
    "        for i, graph in enumerate(graphs):\n",
    "            output, attn_weights, edge_indices = model(graph)  # Model returns output, attention weights, and edge indices\n",
    "            all_outputs.append(output.cpu().numpy())\n",
    "            all_labels.append(labels[i].cpu().numpy())\n",
    "            all_attn_weights.append(attn_weights)\n",
    "            all_edge_indices.append(edge_indices)  # Store edge indices\n",
    "\n",
    "    final_outputs = np.vstack(all_outputs)\n",
    "    final_labels = np.vstack(all_labels)\n",
    "\n",
    "    # Calculate and save performance metrics\n",
    "    compute_and_save_metrics(final_labels, final_outputs, output_dir, data_name)\n",
    "\n",
    "    # Save attention weights for a specific `cpm_id`, if provided\n",
    "    if cpm_id is not None:\n",
    "        output_attention_weights(all_attn_weights, all_edge_indices, graphs, cpm_id, output_dir)\n",
    "\n",
    "# Function to output attention weights with edge indices\n",
    "def output_attention_weights(all_attn_weights, all_edge_indices, graphs, cpm_id, output_dir):\n",
    "    for i, graph in enumerate(graphs):\n",
    "        if hasattr(graph, 'cpm_id') and graph.cpm_id == cpm_id:  # Find the graph with the specified `cpm_id`\n",
    "            attn_weights = all_attn_weights[i]\n",
    "            attn_weights_1 = attn_weights[0]  # Assume correct indexing for the first set of attention weights\n",
    "            attn_weights_1_array = attn_weights_1.cpu().numpy()\n",
    "\n",
    "            # Extract edge indices\n",
    "            edge_indices = all_edge_indices[i].cpu().numpy()\n",
    "\n",
    "            # Get node names\n",
    "            node_names = graph.node_names  # Ensure this attribute is available\n",
    "\n",
    "            # Transpose weights for ease of reading\n",
    "            transposed_weights = attn_weights_1_array.T\n",
    "\n",
    "            # Merge node names with attention weights for easy analysis\n",
    "            merged_array = np.column_stack((node_names, transposed_weights))\n",
    "\n",
    "            # Save as CSV\n",
    "            np.savetxt(os.path.join(output_dir, f'{cpm_id}_attn_weights-transform.csv'), merged_array, delimiter=',', fmt='%s')\n",
    "            print(f\"Attention weights saved as {cpm_id}_attn_weights-transform.csv\")\n",
    "\n",
    "# Function to compute and save various performance metrics and ROC data\n",
    "def compute_and_save_metrics(labels, outputs, output_dir, data_name):\n",
    "    num_classes = labels.shape[1]\n",
    "    metrics = {\n",
    "        'Class': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': [],\n",
    "        'AUC': [],\n",
    "        'Accuracy': [],\n",
    "        'Specificity': []\n",
    "    }\n",
    "    roc_data_long_format = {'Class': [], 'Reference': [], 'Predicted': []}\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        # Apply sigmoid to convert logits to probabilities\n",
    "        probabilities = torch.sigmoid(torch.tensor(outputs))\n",
    "        \n",
    "        # ROC curve and AUC calculation\n",
    "        fpr, tpr, thresholds = roc_curve(labels[:, i], probabilities[:, i].numpy())\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Store ROC data in long format for each class\n",
    "        for ref, pred in zip(labels[:, i], probabilities[:, i].numpy()):\n",
    "            roc_data_long_format['Class'].append(f'Class_{i+1}')\n",
    "            roc_data_long_format['Reference'].append(ref)\n",
    "            roc_data_long_format['Predicted'].append(pred)\n",
    "        \n",
    "        # Calculate Precision, Recall, F1, Accuracy, and Specificity\n",
    "        pred_binary = (probabilities[:, i] > 0.5).numpy().astype(int)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels[:, i], pred_binary, average='binary')\n",
    "        accuracy = accuracy_score(labels[:, i], pred_binary)\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(labels[:, i], pred_binary).ravel()\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "        # Store metrics for each class\n",
    "        metrics['Class'].append(f'Class_{i+1}')\n",
    "        metrics['Precision'].append(precision)\n",
    "        metrics['Recall'].append(recall)\n",
    "        metrics['F1 Score'].append(f1)\n",
    "        metrics['AUC'].append(roc_auc)\n",
    "        metrics['Accuracy'].append(accuracy)\n",
    "        metrics['Specificity'].append(specificity)\n",
    "    \n",
    "    # Calculate average metrics across all classes\n",
    "    avg_metrics = {\n",
    "        'Class': ['Average'],\n",
    "        'Precision': [np.mean(metrics['Precision'])],\n",
    "        'Recall': [np.mean(metrics['Recall'])],\n",
    "        'F1 Score': [np.mean(metrics['F1 Score'])],\n",
    "        'AUC': [np.mean(metrics['AUC'])],\n",
    "        'Accuracy': [np.mean(metrics['Accuracy'])],\n",
    "        'Specificity': [np.mean(metrics['Specificity'])]\n",
    "    }\n",
    "    \n",
    "    # Append average metrics to the metrics dictionary\n",
    "    for key in metrics:\n",
    "        metrics[key].append(avg_metrics[key][0])\n",
    "    \n",
    "    # Save ROC data in long format to CSV\n",
    "    roc_df_long = pd.DataFrame(roc_data_long_format)\n",
    "    roc_df_long.to_csv(os.path.join(output_dir, f'{data_name}_roc_data_transform.csv'), index=False)\n",
    "\n",
    "    # Save metrics data to CSV\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    metrics_df.to_csv(os.path.join(output_dir, f'{data_name}_metrics_transform.csv'), index=False)\n",
    "    print(f\"Metrics and ROC data saved to {output_dir}.\")\n",
    "\n",
    "# Set working directory and define paths for input/output data\n",
    "work_dir = os.getcwd()\n",
    "input_data_dir = os.path.join(work_dir, '../Data')\n",
    "output_dir = os.path.join(work_dir, '../Data')\n",
    "\n",
    "# Evaluate on training, validation, or test sets\n",
    "# evaluate_model(train_graphs, train_labels, model, output_dir, \"train\")\n",
    "# evaluate_model(val_graphs, val_labels, model, output_dir, \"validation\")\n",
    "\n",
    "# Evaluate on test set with a specific `cpm_id`\n",
    "evaluate_model(test_graphs, test_labels, model, output_dir, \"test\", cpm_id='CPM05651')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec6445f-afd1-4eba-83c0-4122d0917bcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
