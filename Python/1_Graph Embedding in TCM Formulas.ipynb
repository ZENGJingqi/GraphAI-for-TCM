{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c01cfc76-f091-47f4-8c2b-7d7033cd8538",
   "metadata": {},
   "source": [
    "# Graph Encoding for Candidate Formula Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e6366-dc5a-4cbc-b794-94cc52ba8ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import networkx as nx\n",
    "import logging\n",
    "from torch_geometric.utils import from_networkx\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Configure logging to log messages to a file\n",
    "logging.basicConfig(filename='graph_processing.log', level=logging.INFO)\n",
    "\n",
    "# Set working directory and define input/output paths\n",
    "work_dir = os.getcwd()  # Use the current directory as work_dir\n",
    "input_data_dir = os.path.join(work_dir, '../Data')  # Set ../Data as input data location\n",
    "output_dir = os.path.join(work_dir, '../Data')  # Set ../Data as input data location\n",
    "\n",
    "# Define specific file paths based on directory settings\n",
    "file_path = os.path.join(input_data_dir, 'Test_input - ‰∏Å.xlsx')\n",
    "output_file = os.path.join(output_dir, 'all_graphs_to_be_predicted.pt')\n",
    "chp_properties_path = os.path.join(input_data_dir, 'CHP_Medicinal_properties.tsv')\n",
    "chp_encoder_path = os.path.join(input_data_dir, 'CHP_Encoder.tsv')\n",
    "\n",
    "# Load data from specified files\n",
    "data = pd.read_excel(file_path)\n",
    "chp_properties_data = pd.read_csv(chp_properties_path, sep='\\t')\n",
    "chp_encoder_data = pd.read_csv(chp_encoder_path, sep='\\t')\n",
    "\n",
    "# Main function to process individual graphs into PyG format\n",
    "def process_graph_to_pyg(cpm_id, cpm_chp_data, chp_properties_data, chp_encoder_data):\n",
    "    try:\n",
    "        # Data preprocessing\n",
    "        chp_properties_data[['x_rank', 'y_rank']] = chp_properties_data[['x_rank', 'y_rank']].apply(pd.to_numeric, errors='coerce')\n",
    "        chp_encoder_data.iloc[:, 1:] = chp_encoder_data.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        # Filter data to specific CPM_ID\n",
    "        cpm_data = cpm_chp_data[cpm_chp_data['CPM_ID'] == cpm_id]\n",
    "\n",
    "        # Initialize an empty graph for current formula\n",
    "        G = nx.MultiGraph()\n",
    "\n",
    "        # Add actual nodes with features, including Dosage_ratio attribute\n",
    "        chp_ids = cpm_data['CHP_ID'].unique()\n",
    "        chp_encoder = chp_encoder_data[chp_encoder_data['CHP_ID'].isin(chp_ids)]\n",
    "        \n",
    "        for _, row in chp_encoder.iterrows():\n",
    "            chp_id = row['CHP_ID']\n",
    "            chp_attr = row[1:].tolist()\n",
    "\n",
    "            # Retrieve Dosage_ratio and handle NaN values by filling with 0\n",
    "            dosage_ratio = cpm_data[cpm_data['CHP_ID'] == chp_id]['Dosage_ratio']\n",
    "            dosage_ratio = pd.to_numeric(dosage_ratio, errors='coerce').fillna(0).iloc[0]\n",
    "            chp_attr.append(dosage_ratio)  # Append Dosage_ratio as last feature\n",
    "\n",
    "            # Add actual node with attributes\n",
    "            G.add_node(chp_id, feature=chp_attr, type='Actual', name=chp_id)\n",
    "\n",
    "        # Add virtual nodes based on actual node features as a template\n",
    "        virtual_node_features = chp_attr.copy()\n",
    "        virtual_nodes = ['Medicinal flavor', 'Meridian tropism', 'Therapeutic nature']\n",
    "        for vn in virtual_nodes:\n",
    "            G.add_node(vn, feature=virtual_node_features, type='Virtual', name=vn)\n",
    "\n",
    "        # Connect actual nodes to virtual nodes\n",
    "        chp_properties = chp_properties_data[chp_properties_data['CHP_ID'].isin(chp_ids)].copy()\n",
    "        chp_properties[['x_rank', 'y_rank']] = chp_properties[['x_rank', 'y_rank']].astype(float) / 23\n",
    "\n",
    "        for _, row in chp_properties.iterrows():\n",
    "            chp_id = row['CHP_ID']\n",
    "            attribute = row[['x_rank', 'y_rank']].tolist()\n",
    "            G.add_edge(chp_id, row['Class'], attr=attribute)  # Connect actual and virtual nodes\n",
    "\n",
    "        # Update virtual node attributes based on connections to actual nodes\n",
    "        update_virtual_node_features(G, virtual_nodes, virtual_node_features)\n",
    "\n",
    "        # Calculate initial attributes for edges between virtual nodes\n",
    "        initial_edge_attrs = calculate_initial_edge_attributes(G, virtual_nodes)\n",
    "\n",
    "        # Add edges between virtual nodes with initial attributes\n",
    "        for i, vn1 in enumerate(virtual_nodes):\n",
    "            for j, vn2 in enumerate(virtual_nodes):\n",
    "                if i < j:\n",
    "                    G.add_edge(vn1, vn2, attr=initial_edge_attrs)\n",
    "\n",
    "        # Convert the undirected graph to a directed graph\n",
    "        G = G.to_directed()\n",
    "\n",
    "        # Ensure symmetry in edge attributes for both directions of each edge\n",
    "        for u, v, k, data in G.edges(keys=True, data=True):\n",
    "            if 'attr' in data:\n",
    "                G.edges[v, u, k]['attr'] = data['attr']\n",
    "\n",
    "        # Convert the graph to a PyG format\n",
    "        pyg_graph = convert_to_pyg_graph(G)\n",
    "\n",
    "        # Add node names and CPM_ID to PyG graph for reference\n",
    "        pyg_graph.node_names = [G.nodes[node]['name'] for node in G.nodes]\n",
    "        pyg_graph.cpm_id = cpm_id\n",
    "\n",
    "        return pyg_graph\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing CPM_ID {cpm_id}: {e}\")\n",
    "        print(f\"Error processing CPM_ID {cpm_id}: {e}\")  # Debug output\n",
    "        return None\n",
    "\n",
    "# Update attributes for virtual nodes based on actual node connections\n",
    "def update_virtual_node_features(G, virtual_nodes, node_attr_names):\n",
    "    for vn in virtual_nodes:\n",
    "        connected_nodes = [node for node in G.neighbors(vn) if G.nodes[node]['type'] == 'Actual']\n",
    "        if connected_nodes:\n",
    "            initial_features = G.nodes[vn]['feature']\n",
    "            weighted_features, total_weight = calculate_weighted_features(G, connected_nodes, vn, node_attr_names)\n",
    "            if total_weight != 0:\n",
    "                updated_features = [wf / total_weight for wf in weighted_features]\n",
    "                G.nodes[vn]['feature'] = [(uf + if_) / 2 for uf, if_ in zip(updated_features, initial_features)]\n",
    "            else:\n",
    "                G.nodes[vn]['feature'] = initial_features\n",
    "\n",
    "# Calculate weighted features for virtual nodes\n",
    "def calculate_weighted_features(G, connected_nodes, vn, node_attr_names):\n",
    "    weighted_features = [0] * len(node_attr_names)\n",
    "    total_weight = 0\n",
    "    for node in connected_nodes:\n",
    "        node_features = G.nodes[node]['feature']\n",
    "        edge_data = G.get_edge_data(node, vn)\n",
    "        for edge_key in edge_data:\n",
    "            edge_attr = edge_data[edge_key]['attr']\n",
    "            for ea in edge_attr:\n",
    "                weighted_features = [wf + f * ea for wf, f in zip(weighted_features, node_features)]\n",
    "                total_weight += ea\n",
    "    return weighted_features, total_weight\n",
    "\n",
    "# Calculate average edge attributes for initial connections between virtual nodes\n",
    "def calculate_initial_edge_attributes(G, virtual_nodes):\n",
    "    initial_edge_attrs = []\n",
    "    for vn in virtual_nodes:\n",
    "        for node in G.neighbors(vn):\n",
    "            if G.nodes[node]['type'] == 'Actual':\n",
    "                edge_data = G.get_edge_data(node, vn)\n",
    "                for edge_key in edge_data:\n",
    "                    edge_attr = edge_data[edge_key]['attr']\n",
    "                    initial_edge_attrs.append(edge_attr)\n",
    "    avg_initial_edge_attr = [sum(x) / len(initial_edge_attrs) for x in zip(*initial_edge_attrs)]\n",
    "    return avg_initial_edge_attr\n",
    "\n",
    "# Convert networkx graph to PyTorch Geometric format with features and edge attributes\n",
    "def convert_to_pyg_graph(G):\n",
    "    pyg_graph = from_networkx(G)\n",
    "    pyg_graph.x = torch.tensor([G.nodes[node]['feature'] for node in G.nodes], dtype=torch.float)\n",
    "    pyg_graph.edge_attr = torch.tensor([G.edges[edge]['attr'] for edge in G.edges], dtype=torch.float)\n",
    "    pyg_graph.node_types = [G.nodes[node]['type'] for node in G.nodes]\n",
    "    return pyg_graph\n",
    "\n",
    "# Process graphs concurrently and save results\n",
    "pyg_graphs = []\n",
    "unique_cpm_ids = data['CPM_ID'].unique()\n",
    "\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    futures = [\n",
    "        executor.submit(\n",
    "            process_graph_to_pyg,\n",
    "            cpm_id,\n",
    "            data[data['CPM_ID'] == cpm_id],\n",
    "            chp_properties_data,\n",
    "            chp_encoder_data\n",
    "        ) for cpm_id in unique_cpm_ids\n",
    "    ]\n",
    "    \n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Processing graphs\"):\n",
    "        result = future.result()\n",
    "        if result is not None:\n",
    "            pyg_graphs.append(result)\n",
    "\n",
    "# Save the processed PyG graphs to a file\n",
    "torch.save(pyg_graphs, output_file)\n",
    "print(f\"Successfully saved {len(pyg_graphs)} graphs to '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bc1ca0-ac73-46d8-ad7e-42bf3bea2855",
   "metadata": {},
   "source": [
    "# Examine Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f3108-6f84-4d70-bdbd-68726dc1c5e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Set working directory and define input/output paths\n",
    "work_dir = os.getcwd()  # Use the current directory as work_dir\n",
    "input_data_dir = os.path.join(work_dir, '../Data')  # Set ../Data as input data location\n",
    "output_dir = os.path.join(work_dir, '../Data')  # Set ../Data as input data location\n",
    "\n",
    "# Load PyG graphs from the specified file\n",
    "output_file = os.path.join(input_data_dir, 'all_graphs_to_be_predicted.pt')\n",
    "loaded_pyg_graphs = torch.load(output_file, weights_only=False)\n",
    "\n",
    "# Check and display the number of graphs loaded\n",
    "num_graphs = len(loaded_pyg_graphs)\n",
    "print(f\"Number of graphs: {num_graphs}\")\n",
    "\n",
    "# Display the number of label columns in each graph (if labels are present)\n",
    "if len(loaded_pyg_graphs) > 0:\n",
    "    first_graph = loaded_pyg_graphs[0]\n",
    "    num_label_columns = first_graph.y.size(0) if first_graph.y is not None else 0\n",
    "    print(f\"Number of label columns: {num_label_columns}\")\n",
    "\n",
    "# Display detailed information for the first graph (index can be changed as needed)\n",
    "graph_index = 1  # Modify this index to view other graphs if needed\n",
    "first_graph = loaded_pyg_graphs[graph_index]\n",
    "print(f\"\\nDetails for Graph {graph_index + 1}:\")\n",
    "\n",
    "# Display node features\n",
    "print(f\"Node Features:\\n{first_graph.x}\")\n",
    "\n",
    "# Display edge index (connections between nodes)\n",
    "print(f\"Edge Index:\\n{first_graph.edge_index}\")\n",
    "\n",
    "# Display edge attributes if present\n",
    "if hasattr(first_graph, 'edge_attr'):\n",
    "    print(f\"Edge Attributes:\\n{first_graph.edge_attr}\")\n",
    "else:\n",
    "    print(\"No Edge Attributes\")\n",
    "\n",
    "# Display labels if present\n",
    "if hasattr(first_graph, 'y'):\n",
    "    print(f\"Labels:\\n{first_graph.y}\")\n",
    "else:\n",
    "    print(\"No Labels\")\n",
    "\n",
    "# Display CPM_ID if present\n",
    "if hasattr(first_graph, 'cpm_id'):\n",
    "    print(f\"CPM_ID: {first_graph.cpm_id}\")\n",
    "else:\n",
    "    print(\"No CPM_ID\")\n",
    "\n",
    "# Display node names if present\n",
    "if hasattr(first_graph, 'node_names'):\n",
    "    print(f\"Node Names:\\n{first_graph.node_names}\")\n",
    "else:\n",
    "    print(\"No Node Names\")\n",
    "\n",
    "# Display node types if present\n",
    "if hasattr(first_graph, 'node_types'):\n",
    "    print(f\"Node Types:\\n{first_graph.node_types}\")\n",
    "else:\n",
    "    print(\"No Node Types\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3f00b8-66e9-4bd9-8ac2-321ca3c62f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
