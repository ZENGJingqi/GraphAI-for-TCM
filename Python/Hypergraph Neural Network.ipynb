{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f77bed1-88d5-4062-8522-0cd1d2e40a45",
   "metadata": {},
   "source": [
    "# Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f4b746c-f1ba-4046-9d5c-c80519117f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 4256 graphs\n",
      "Validation set: 1222 graphs\n",
      "Test set: 602 graphs\n",
      "Proportion of '1's for each label in training set: [0.06343985 0.06414474 0.57307331 0.10103383 0.30451128]\n",
      "Proportion of '1's for each label in validation set: [0.06873977 0.06792144 0.57774141 0.09165303 0.30032733]\n",
      "Proportion of '1's for each label in test set: [0.04318937 0.06644518 0.57807309 0.09966777 0.3255814 ]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set working directory and define paths for input and output data\n",
    "work_dir = os.getcwd()  # Use the current directory as work_dir\n",
    "input_data_dir = os.path.join(work_dir, '../Data')  # Set ../Data as input data location\n",
    "output_dir = os.path.join(work_dir, '../Data')  # Set ../Data as output data location\n",
    "\n",
    "# Define the path to the file containing labeled hypergraphs\n",
    "hypergraph_file = os.path.join(input_data_dir, 'all_hypergraphs_with_labels-train.pkl')\n",
    "\n",
    "# Load the hypergraph data from file\n",
    "hypergraphs = torch.load(hypergraph_file)\n",
    "\n",
    "# Extract labels from each hypergraph, converting each to a NumPy array for easy handling\n",
    "# Each hypergraph is assumed to have a `labels` attribute for its label(s)\n",
    "labels = np.array([\n",
    "    hypergraph.labels.numpy() if isinstance(hypergraph.labels, torch.Tensor) else hypergraph.labels \n",
    "    for hypergraph in hypergraphs\n",
    "])\n",
    "\n",
    "# Function to perform a random train-test split\n",
    "def random_train_test_split(graphs, labels, test_size=0.3, random_state=42):\n",
    "    \"\"\"Splits graphs and labels into training and testing sets using random split\"\"\"\n",
    "    train_graphs, test_graphs, train_labels, test_labels = train_test_split(\n",
    "        graphs, labels, test_size=test_size, random_state=random_state, shuffle=True)\n",
    "\n",
    "    return train_graphs, test_graphs, train_labels, test_labels\n",
    "\n",
    "# Split dataset into training (70%) and temporary (30%) sets\n",
    "train_graphs, temp_graphs, train_labels, temp_labels = random_train_test_split(\n",
    "    hypergraphs, labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Further split the temporary set (30%) into validation (20%) and test sets (10%)\n",
    "val_graphs, test_graphs, val_labels, test_labels = random_train_test_split(\n",
    "    temp_graphs, temp_labels, test_size=0.33, random_state=42\n",
    ")\n",
    "\n",
    "# Function to calculate the proportion of '1's in each label across a set of labels\n",
    "def calculate_label_proportions(labels):\n",
    "    proportions = np.mean(labels == 1, axis=0)  # Calculate the proportion of '1's for each label\n",
    "    return proportions\n",
    "\n",
    "# Calculate the proportion of '1's in each subset's labels\n",
    "train_proportions = calculate_label_proportions(train_labels)\n",
    "val_proportions = calculate_label_proportions(val_labels)\n",
    "test_proportions = calculate_label_proportions(test_labels)\n",
    "\n",
    "# Convert labels back to torch.Tensor format for PyTorch model compatibility\n",
    "train_labels = torch.tensor(train_labels)\n",
    "val_labels = torch.tensor(val_labels)\n",
    "test_labels = torch.tensor(test_labels)\n",
    "\n",
    "# Print the size of each subset\n",
    "print(f\"Training set: {len(train_graphs)} graphs\")\n",
    "print(f\"Validation set: {len(val_graphs)} graphs\")\n",
    "print(f\"Test set: {len(test_graphs)} graphs\")\n",
    "\n",
    "# Print the proportion of '1's for each label in each subset\n",
    "print(\"Proportion of '1's for each label in training set:\", train_proportions)\n",
    "print(\"Proportion of '1's for each label in validation set:\", val_proportions)\n",
    "print(\"Proportion of '1's for each label in test set:\", test_proportions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720ada1b-d418-4776-9704-c22d0f7eef8b",
   "metadata": {},
   "source": [
    "# Hypergraph Neural Network Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0672640-2760-4a8a-827e-1d99e3984d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Set random seed for reproducibility across random, numpy, and PyTorch functions\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)  # Set seed to 42 for consistency\n",
    "\n",
    "# Define a hypergraph convolution layer with attention mechanism\n",
    "class HypergraphAttentionConv(nn.Module):\n",
    "    def __init__(self, in_features, out_features, num_heads=1):\n",
    "        super(HypergraphAttentionConv, self).__init__()\n",
    "        self.num_heads = num_heads  # Number of attention heads\n",
    "        # Create multiple attention heads, each mapping input to output features\n",
    "        self.attention_heads = nn.ModuleList([nn.Linear(in_features, out_features) for _ in range(num_heads)])\n",
    "        self.fc = nn.Linear(out_features, out_features)  # Final linear layer to combine head outputs\n",
    "\n",
    "    def forward(self, x, H):\n",
    "        \"\"\"\n",
    "        Forward pass through the attention-based hypergraph convolution.\n",
    "        - x: Node feature matrix\n",
    "        - H: Hypergraph incidence matrix\n",
    "        \"\"\"\n",
    "        hyperedge_features = []\n",
    "        attn_weights = []\n",
    "        \n",
    "        # Process each attention head\n",
    "        for attn_head in self.attention_heads:\n",
    "            # Compute hyperedge features with attention\n",
    "            hyperedge_feat = torch.matmul(H.T, F.elu(attn_head(x)))  # Apply attention head, then non-linearity\n",
    "            hyperedge_features.append(hyperedge_feat)\n",
    "\n",
    "            # Calculate attention weights\n",
    "            attn_weight = F.softmax(torch.matmul(H.T, attn_head(x)), dim=0)\n",
    "            attn_weights.append(attn_weight)\n",
    "\n",
    "        # Aggregate hyperedge features across heads by averaging\n",
    "        hyperedge_features = torch.stack(hyperedge_features, dim=0).mean(dim=0)\n",
    "        \n",
    "        # Compute node features by multiplying with incidence matrix and final linear layer\n",
    "        x = torch.matmul(H, hyperedge_features)\n",
    "        x = self.fc(x)  # Final output layer\n",
    "        return x, torch.mean(torch.stack(attn_weights), dim=0)  # Return output and average attention weights\n",
    "\n",
    "# Define the HGNN model with two hypergraph convolutional layers and attention\n",
    "class TwoLayerHGNNWithAttention(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, out_features, dropout=0.5, num_heads=8, dosage_weight=1.0):\n",
    "        super(TwoLayerHGNNWithAttention, self).__init__()\n",
    "        self.dosage_weight = dosage_weight  # Weight for dosage feature\n",
    "        # First hypergraph attention layer\n",
    "        self.conv1 = HypergraphAttentionConv(in_features, hidden_features, num_heads=num_heads)\n",
    "        self.dropout1 = nn.Dropout(dropout)  # Dropout for regularization\n",
    "        # Second hypergraph attention layer\n",
    "        self.conv2 = HypergraphAttentionConv(hidden_features, hidden_features, num_heads=1)\n",
    "        self.dropout2 = nn.Dropout(dropout)  # Dropout for regularization\n",
    "        self.fc = nn.Linear(hidden_features, out_features)  # Fully connected output layer\n",
    "\n",
    "    def forward(self, x, H):\n",
    "        \"\"\"\n",
    "        Forward pass for the HGNN model.\n",
    "        - x: Node feature matrix\n",
    "        - H: Hypergraph incidence matrix\n",
    "        \"\"\"\n",
    "        # Apply dosage weight to feature at index 90\n",
    "        x[:, 90] = torch.clamp(x[:, 90] * self.dosage_weight, min=0, max=10)\n",
    "        \n",
    "        # First attention layer with activation and dropout\n",
    "        x, attn_weights1 = self.conv1(x, H)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        # Second attention layer with activation and dropout\n",
    "        x, attn_weights2 = self.conv2(x, H)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        # Apply global average pooling to reduce features to a single vector\n",
    "        x = torch.mean(x, dim=0)  # Output shape: [hidden_features]\n",
    "\n",
    "        # Final fully connected layer for output prediction\n",
    "        x = self.fc(x)  # Output shape: [out_features]\n",
    "        return x, attn_weights1, attn_weights2  # Return output and attention weights from both layers\n",
    "\n",
    "# Model parameters\n",
    "in_features = 91          # Input feature dimension\n",
    "hidden_features = 96      # Hidden layer dimension\n",
    "out_features = 5          # Output dimension (e.g., number of classes)\n",
    "dropout = 0.5             # Dropout rate\n",
    "num_heads = 4             # Number of attention heads\n",
    "dosage_weight = 1.0       # Weight factor for dosage feature\n",
    "\n",
    "# Instantiate the HGNN model\n",
    "model = TwoLayerHGNNWithAttention(in_features, hidden_features, out_features, dropout, num_heads, dosage_weight)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dbf999-0016-4c56-9778-dbf41a402a2c",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d637e7-a1bb-4d3b-9086-b84ade901f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Set class weights to handle label imbalance\n",
    "def compute_class_weights(labels):\n",
    "    num_classes = labels.size(1)\n",
    "    pos_counts = labels.sum(dim=0)\n",
    "    neg_counts = labels.size(0) - pos_counts\n",
    "    pos_weight = neg_counts / (pos_counts + 1e-6)  # Avoid division by zero with small constant\n",
    "    return pos_weight\n",
    "\n",
    "# Define loss function, optimizer, and learning rate scheduler\n",
    "pos_weight = compute_class_weights(train_labels)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)  # Use BCEWithLogitsLoss for multi-label classification\n",
    "learning_rate = 0.0005\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)  # Reduce LR on plateau in validation loss\n",
    "\n",
    "# Early stopping mechanism to halt training if validation loss does not improve\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or self.best_loss - val_loss > self.min_delta:\n",
    "            self.best_loss = val_loss  # Update best loss\n",
    "            self.counter = 0  # Reset counter if validation loss improves\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True  # Trigger early stopping if patience is exceeded\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5, min_delta=0.001)\n",
    "\n",
    "# Construct hypergraph incidence matrix for a given hypergraph\n",
    "def construct_hypergraph_incidence_matrix(hypergraph):\n",
    "    node_indices, edge_indices, values = [], [], []\n",
    "    node_dict = {node: idx for idx, node in enumerate(hypergraph.nodes)}  # Map nodes to indices\n",
    "    for j, edge in enumerate(hypergraph.edges):\n",
    "        for node in hypergraph.edges[edge]:\n",
    "            i = node_dict[node]\n",
    "            node_indices.append(i)\n",
    "            edge_indices.append(j)\n",
    "            values.append(1.0)  # Set connection value to 1.0\n",
    "    indices = torch.LongTensor([node_indices, edge_indices])\n",
    "    values = torch.FloatTensor(values)\n",
    "    H = torch.sparse_coo_tensor(indices, values, (len(hypergraph.nodes), len(hypergraph.edges)))\n",
    "    return H\n",
    "\n",
    "# Generator function to yield batches of data and labels\n",
    "def batchify(data, labels, batch_size):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i + batch_size], labels[i:i + batch_size]\n",
    "\n",
    "# Print the current learning rate from the optimizer\n",
    "def print_learning_rate(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(f\"Current Learning Rate: {param_group['lr']}\")\n",
    "\n",
    "# Train model for a single epoch\n",
    "def train_epoch(graphs, labels, batch_size, loss_fn, grad_clip_value=1.0):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "    batches = list(batchify(graphs, labels, batch_size))\n",
    "    pbar = tqdm(total=len(batches), desc=\"Training\")\n",
    "    \n",
    "    for batch_graphs, batch_labels in batches:\n",
    "        optimizer.zero_grad()  # Clear gradients\n",
    "        batch_loss = 0\n",
    "        for i, graph in enumerate(batch_graphs):\n",
    "            # Stack node features and construct incidence matrix\n",
    "            x = torch.stack([graph.node_features[node].float() for node in graph.nodes])\n",
    "            H = construct_hypergraph_incidence_matrix(graph)\n",
    "            output, attn_weights1, attn_weights2 = model(x, H)\n",
    "            \n",
    "            # Compute loss between model output and labels\n",
    "            loss = loss_fn(output.view(1, -1), batch_labels[i].view(1, -1).float())\n",
    "            batch_loss += loss\n",
    "        batch_loss.backward()  # Backpropagate loss\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_value)  # Clip gradients\n",
    "        optimizer.step()  # Update parameters\n",
    "        total_loss += batch_loss.item()\n",
    "        pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    return total_loss / len(graphs)  # Return average loss for the epoch\n",
    "\n",
    "# Validation function to evaluate model on validation set\n",
    "def validate(graphs, labels, loss_fn):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for i, graph in enumerate(graphs):\n",
    "            # Stack node features and construct incidence matrix\n",
    "            x = torch.stack([graph.node_features[node].float() for node in graph.nodes])\n",
    "            H = construct_hypergraph_incidence_matrix(graph)\n",
    "            output, attn_weights1, attn_weights2 = model(x, H)\n",
    "            \n",
    "            # Compute validation loss\n",
    "            loss = loss_fn(output.view(1, -1), labels[i].view(1, -1).float())\n",
    "            total_loss += loss.item()\n",
    "            all_outputs.append(torch.sigmoid(output).cpu().numpy())\n",
    "            all_labels.append(labels[i].cpu().numpy())\n",
    "\n",
    "    all_outputs = np.vstack(all_outputs)  # Stack all outputs\n",
    "    all_labels = np.vstack(all_labels)  # Stack all labels\n",
    "    \n",
    "    # Calculate recall and F1 score\n",
    "    recall = recall_score(all_labels, all_outputs.round(), average='micro')\n",
    "    f1 = f1_score(all_labels, all_outputs.round(), average='micro')\n",
    "    \n",
    "    return total_loss / len(graphs), recall, f1\n",
    "\n",
    "# Wrapper function to train and validate the model across epochs\n",
    "def train_model(train_graphs, train_labels, val_graphs, val_labels, model, loss_fn, optimizer, scheduler, num_epochs=50, batch_size=16):\n",
    "    train_losses, val_losses, val_recalls, val_f1s = [], [], [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        train_loss = train_epoch(train_graphs, train_labels, batch_size, loss_fn)  # Train for one epoch\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validate the model\n",
    "        val_loss, val_recall, val_f1 = validate(val_graphs, val_labels, loss_fn)\n",
    "        val_losses.append(val_loss)\n",
    "        val_recalls.append(val_recall)\n",
    "        val_f1s.append(val_f1)\n",
    "        \n",
    "        scheduler.step(val_loss)  # Adjust learning rate based on validation loss\n",
    "        print(f\"Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, \"\n",
    "              f\"Validation Recall: {val_recall:.4f}, Validation F1: {val_f1:.4f}\")\n",
    "\n",
    "        print_learning_rate(optimizer)  # Print current learning rate\n",
    "\n",
    "        early_stopping(val_loss)  # Check for early stopping\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "# Train the model\n",
    "train_model(train_graphs, train_labels, val_graphs, val_labels, model, loss_fn, optimizer, scheduler, num_epochs=30, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7814d5a-f72e-4891-8718-956754833c23",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f0db2c-d1be-49b4-b66d-557eb4378834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_fscore_support, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import rcParams\n",
    "\n",
    "# Set global font to Arial for consistent plotting\n",
    "rcParams['font.family'] = 'Arial'\n",
    "\n",
    "# Function to evaluate the model on a specific dataset\n",
    "def evaluate_model(graphs, labels, model, output_dir, data_name):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Collect predictions and labels for the specified dataset\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Disable gradient calculations for evaluation\n",
    "    with torch.no_grad():\n",
    "        for i, graph in enumerate(graphs):\n",
    "            x = torch.stack([graph.node_features[node] for node in graph.nodes])  # Extract node features\n",
    "            H = construct_hypergraph_incidence_matrix(graph)  # Construct hypergraph incidence matrix\n",
    "            output, attn_weights1, _ = model(x, H)  # Get model output, taking only `output`\n",
    "            \n",
    "            all_outputs.append(output.cpu().numpy())\n",
    "            all_labels.append(labels[i].cpu().numpy())\n",
    "\n",
    "    # Convert predictions and labels to NumPy arrays\n",
    "    final_outputs = np.vstack(all_outputs)\n",
    "    final_labels = np.vstack(all_labels)\n",
    "\n",
    "    # Compute and save evaluation metrics\n",
    "    compute_and_save_metrics(final_labels, final_outputs, output_dir, data_name)\n",
    "\n",
    "\n",
    "# Function to compute and save various performance metrics and ROC data\n",
    "def compute_and_save_metrics(labels, outputs, output_dir, data_name):\n",
    "    num_classes = labels.shape[1]\n",
    "    metrics = {\n",
    "        'Class': [],\n",
    "        'Precision': [],\n",
    "        'Recall': [],\n",
    "        'F1 Score': [],\n",
    "        'AUC': [],\n",
    "        'Accuracy': [],\n",
    "        'Specificity': []\n",
    "    }\n",
    "    roc_data_long_format = {'Class': [], 'Reference': [], 'Predicted': []}\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        # Apply sigmoid to convert logits to probabilities\n",
    "        probabilities = torch.sigmoid(torch.tensor(outputs))  # Convert logits to probabilities in range 0-1\n",
    "        \n",
    "        # ROC curve and AUC calculation\n",
    "        fpr, tpr, thresholds = roc_curve(labels[:, i], probabilities[:, i].numpy())\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Save true labels and predicted probabilities for ROC data in long format\n",
    "        for ref, pred in zip(labels[:, i], probabilities[:, i].numpy()):\n",
    "            roc_data_long_format['Class'].append(f'Class_{i+1}')\n",
    "            roc_data_long_format['Reference'].append(ref)\n",
    "            roc_data_long_format['Predicted'].append(pred)\n",
    "        \n",
    "        # Calculate Precision, Recall, F1 Score, Accuracy, and Specificity\n",
    "        pred_binary = (probabilities[:, i] > 0.5).numpy().astype(int)  # Use threshold 0.5 for binary predictions\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels[:, i], pred_binary, average='binary')\n",
    "        accuracy = accuracy_score(labels[:, i], pred_binary)\n",
    "        \n",
    "        tn, fp, fn, tp = confusion_matrix(labels[:, i], pred_binary).ravel()\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # Prevent division by zero\n",
    "\n",
    "        # Save metrics for the current class\n",
    "        metrics['Class'].append(f'Class_{i+1}')\n",
    "        metrics['Precision'].append(precision)\n",
    "        metrics['Recall'].append(recall)\n",
    "        metrics['F1 Score'].append(f1)\n",
    "        metrics['AUC'].append(roc_auc)\n",
    "        metrics['Accuracy'].append(accuracy)\n",
    "        metrics['Specificity'].append(specificity)\n",
    "    \n",
    "    # Compute average metrics across all classes\n",
    "    avg_metrics = {\n",
    "        'Class': ['Average'],\n",
    "        'Precision': [np.mean(metrics['Precision'])],\n",
    "        'Recall': [np.mean(metrics['Recall'])],\n",
    "        'F1 Score': [np.mean(metrics['F1 Score'])],\n",
    "        'AUC': [np.mean(metrics['AUC'])],\n",
    "        'Accuracy': [np.mean(metrics['Accuracy'])],\n",
    "        'Specificity': [np.mean(metrics['Specificity'])]\n",
    "    }\n",
    "    \n",
    "    # Add average metrics to the metrics dictionary\n",
    "    for key in metrics:\n",
    "        metrics[key].append(avg_metrics[key][0])\n",
    "    \n",
    "    # Save ROC data in long format to CSV\n",
    "    roc_df_long = pd.DataFrame(roc_data_long_format)\n",
    "    roc_df_long.to_csv(os.path.join(output_dir, f'{data_name}_roc_data_hypergraph.csv'), index=False)\n",
    "\n",
    "    # Save evaluation metrics to CSV\n",
    "    metrics_df = pd.DataFrame(metrics)\n",
    "    metrics_df.to_csv(os.path.join(output_dir, f'{data_name}_metrics_hypergraph.csv'), index=False)\n",
    "    print(f\"Metrics and ROC data saved to {output_dir}.\")\n",
    "\n",
    "\n",
    "# Set working directory and define input/output paths\n",
    "work_dir = os.getcwd()  # Use the current directory as work_dir\n",
    "input_data_dir = os.path.join(work_dir, '../Data')  # Set ../Data as input data location\n",
    "output_dir = os.path.join(work_dir, '../Data')  # Set ../Data as output data location\n",
    "\n",
    "# Evaluate model on training set\n",
    "#evaluate_model(train_graphs, train_labels, model, output_dir, \"train\")\n",
    "\n",
    "# Evaluate model on validation set\n",
    "#evaluate_model(val_graphs, val_labels, model, output_dir, \"validation\")\n",
    "\n",
    "# Evaluate model on test set\n",
    "evaluate_model(test_graphs, test_labels, model, output_dir, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6471dc-1e11-4ff6-ada3-ee07397daddf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
